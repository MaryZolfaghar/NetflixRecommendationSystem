{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Predict ratings using Matrix Completion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------------------------------------------------------#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import argparse\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from scipy.sparse.linalg import svds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class arguments():\n",
    "    # Set Path\n",
    "    DATAPATH = '../../datasets/'\n",
    "    RESULTPATH = '../results/'\n",
    "    metadata = 'False'\n",
    "    fillnan='mean_col'\n",
    "    sim_method='cosine_similarity'\n",
    "    norm_laplacian_k=5\n",
    "    normalize_laplacian='False'\n",
    "    kmeans_k=5\n",
    "    n_epochs=10\n",
    "    test_prc=0.25\n",
    "    graph_nodes='M'\n",
    "    \n",
    "args = arguments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reading and preprocessing data\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "def read_preprocss_data(args):\n",
    "    time_start=time.time()\n",
    "    # args.DATAPATH = '../datasets/'\n",
    "    train = pd.read_csv(args.DATAPATH + 'train.csv')\n",
    "    test = pd.read_csv(args.DATAPATH + 'test.csv')\n",
    "\n",
    "    train.columns = ['movie_id', 'customer_id', 'rating', 'date']\n",
    "    test.columns  = ['movie_id', 'customer_id', 'rating', 'date']\n",
    "\n",
    "    df = train.pivot_table(index='customer_id', \\\n",
    "                               columns='movie_id', values='rating', aggfunc=np.mean).fillna(0)\n",
    "    A_fill_zeros = df.to_numpy().copy()\n",
    "\n",
    "    if args.fillnan=='mean_col':\n",
    "        df = train.pivot_table(index='customer_id', \\\n",
    "                               columns='movie_id', values='rating', aggfunc=np.mean)\n",
    "        A = df.to_numpy().copy()\n",
    "        # column mean\n",
    "        col_mean = np.nanmean(A, axis = 0)\n",
    "        col_mean = np.ceil(col_mean)\n",
    "        print(col_mean.shape)\n",
    "        col_mean[col_mean>5]=5\n",
    "        # find indices where nan value is present\n",
    "        inds = np.where(np.isnan(A))\n",
    "        # replace inds with avg of column\n",
    "        A[inds] = np.take(col_mean, inds[1])\n",
    "    elif args.fillnan=='mean_row':\n",
    "        df = train.pivot_table(index='customer_id', \\\n",
    "                               columns='movie_id', values='rating', aggfunc=np.mean)\n",
    "        A = df.to_numpy().copy()\n",
    "        # row mean\n",
    "        row_mean = np.nanmean(A, axis = 1)\n",
    "        row_mean = np.ceil(row_mean)\n",
    "        # find indices where nan value is present\n",
    "        inds = np.where(np.isnan(A))\n",
    "        # replace inds with avg of column\n",
    "        A[inds] = np.take(row_mean, inds[1])\n",
    "\n",
    "    print('Reading time elapsed: {} sec'.format(time.time()-time_start))\n",
    "    print('Reading is done, the shape of the data is:', A.shape)\n",
    "    \n",
    "\n",
    "    return df, A, A_fill_zeros\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Generating similarity matrix\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.metrics.pairwise import sigmoid_kernel, cosine_similarity\n",
    "\n",
    "\n",
    "def gen_similarity(args, X):\n",
    "\n",
    "    if args.sim_method=='sigmoid_kernel':\n",
    "        sim_UXU=sigmoid_kernel(X=X, Y=None, gamma=None, coef0=1)\n",
    "        sim_MXM=sigmoid_kernel(X=X.T, Y=None, gamma=None, coef0=1)\n",
    "    elif args.sim_method=='cosine_similarity':\n",
    "        sim_UXU=cosine_similarity(X=X, Y=None)\n",
    "        sim_MXM=cosine_similarity(X=X.T, Y=None)\n",
    "    ## =====================================================================\n",
    "#     # Save similarity matrix\n",
    "#     fn_str = args.RESULTPATH + 'sim_%s_UXU.npy' %(args.sim_method)\n",
    "#     with open(fn_str, 'wb') as f:\n",
    "#         pickle.dump(sim_UXU, f)\n",
    "\n",
    "#     fn_str = args.RESULTPATH + 'sim_%s_MXM.npy' %(args.sim_method)\n",
    "#     with open(fn_str, 'wb') as f:\n",
    "#         pickle.dump(sim_MXM, f)\n",
    "#     print('saving similarity matrix is done!')\n",
    "    ## =====================================================================\n",
    "    return sim_UXU, sim_MXM\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculating the Laplacian matrix\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "def calc_laplacian(args, Ws):\n",
    "    t1 = time.time()\n",
    "    # degree matrix\n",
    "    D = np.diag(np.sum(np.array(Ws), axis=1))\n",
    "    print('degree matrix:')\n",
    "    print(D.shape)\n",
    "    # laplacian matrix\n",
    "    L = D - Ws\n",
    "    print('laplacian matrix:')\n",
    "    print(L.shape)\n",
    "    elapsed_time = time.time() - t1\n",
    "    print('Elapsed time is {} seconds: '.format(elapsed_time))\n",
    "\n",
    "    return L, D\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Calculate eigen vectors and values of the input\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# from numpy import linalg as LA\n",
    "# from scipy.sparse import linalg\n",
    "# from scipy.linalg import eig as LAeig\n",
    "# from scipy import linalg\n",
    "from scipy.sparse.linalg import eigsh\n",
    "\n",
    "\n",
    "def calc_eig(args, L, Ws, kk):\n",
    "    t1 = time.time()\n",
    "    D=np.diag(np.sum(Ws, axis=0))\n",
    "    vol=np.sum(np.diag(D))\n",
    "\n",
    "    vals, vecs = eigsh(L, k=kk, which=\"SM\")  # Largest 5 eigenvalues/vectors\n",
    "    vecs = vecs.real\n",
    "\n",
    "    print('the first 10 eigen values are:')\n",
    "    print(vals[:10])\n",
    "    print('\\n')\n",
    "\n",
    "    if (vals[0]==0):\n",
    "        if vals[1] > 0:\n",
    "            print('OOOPS the first eigen value was zero')\n",
    "            vals = vals[1:]\n",
    "            vecs = vecs[:,1:]\n",
    "    if (vals[0]<1e-10):\n",
    "        print('OOOPS the first eigen value was so small')\n",
    "        vals = vals[1:]\n",
    "        vecs = vecs[:,1:]\n",
    "\n",
    "    #caluclate eigen gap\n",
    "    e1 = np.zeros([vals.shape[0]+1])\n",
    "    e2 = np.zeros([vals.shape[0]+1])\n",
    "    print(e1.shape)\n",
    "    e1[1:] = vals.copy()\n",
    "    e2[:-1] = vals.copy()\n",
    "    print('eigen gap is:')\n",
    "    eigengap=(e2-e1)\n",
    "    print(eigengap)\n",
    "    print('the first 10 eigen values are:')\n",
    "    print(vals[:10])\n",
    "    print('\\n')\n",
    "    #\n",
    "\n",
    "\n",
    "    # eigenvalues\n",
    "    print('eigenvalues shape is:')\n",
    "    print(vals.shape)\n",
    "    # eigenvectors\n",
    "    print('eigenvectors shape is :')\n",
    "    print(vecs.shape)\n",
    "    if args.normalize_laplacian:\n",
    "        print('do the normalization')\n",
    "        Y = np.sort(vals)\n",
    "        I = np.argsort(vals)\n",
    "        v_norm = vecs[:,I[:args.norm_laplacian_k]] \\\n",
    "            / LA.norm(vecs[:,I[:args.norm_laplacian_k]])*vol**(1/2)\n",
    "    else:\n",
    "        v_norm = []\n",
    "    elapsed_time = time.time() - t1\n",
    "    print('Elapsed time is {} seconds: '.format(elapsed_time))\n",
    "    print('calc eigen vectors and values done!')\n",
    "    return vals, vecs, v_norm, eigengap\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16142,)\n",
      "Reading time elapsed: 31.96229100227356 sec\n",
      "Reading is done, the shape of the data is: (5905, 16142)\n",
      "done reading the data\n",
      "data shape is: (5905, 16142)\n",
      "data fill zero shape is: (5905, 16142)\n"
     ]
    }
   ],
   "source": [
    "df, A, A_fill_zeros = read_preprocss_data(args)\n",
    "print('done reading the data')\n",
    "\n",
    "data = A.copy()\n",
    "data_fill_zeros = A_fill_zeros.copy()\n",
    "print('data shape is:', data.shape)\n",
    "print('data fill zero shape is:', data_fill_zeros.shape)\n",
    "#===========================================================================\n",
    "#=======================================================================\n",
    "test = pd.read_csv(args.DATAPATH + 'test.csv')\n",
    "test.columns  = ['movie_id', 'customer_id', 'rating', 'date']\n",
    "test_np = test.to_numpy().copy()\n",
    "\n",
    "train = pd.read_csv(args.DATAPATH + 'train.csv')\n",
    "train.columns  = ['movie_id', 'customer_id', 'rating', 'date']\n",
    "train_np = train.to_numpy().copy()\n",
    "\n",
    "train_data = data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_index = {movie:indx for indx, movie in enumerate(df.columns.values)}\n",
    "customer_to_index = {customer:indx for indx, customer in enumerate(df.index.values)}\n",
    "index_to_movie = {indx:movie for indx, movie in enumerate(df.columns.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pred_ratings time elapsed: 6.426725149154663 sec\n"
     ]
    }
   ],
   "source": [
    "#=======================================================================\n",
    "final_k = 5\n",
    "#=======================================================================\n",
    "time_start=time.time()\n",
    "\n",
    "train_data = data.copy()\n",
    "U, sigmaTmp, Vt = svds(train_data, k = final_k)\n",
    "sigma = np.zeros([sigmaTmp.shape[0], sigmaTmp.shape[0]])\n",
    "np.fill_diagonal(sigma, sigmaTmp)\n",
    "pred_ratings = np.dot(np.dot(U, sigma), Vt)\n",
    "print('pred_ratings time elapsed: {} sec'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if args.graph_nodes=='M': # menas the sim is MXM\n",
    "    \n",
    "#     time_start=time.time()\n",
    "#     existed=0\n",
    "#     for ic in range(len(test_np)):    \n",
    "#         mvid   = test_np[ic, 0]\n",
    "#         custid = test_np[ic, 1]\n",
    "#         if mvid not in movie_to_index.keys():\n",
    "#             test_np[ic,2] = -1\n",
    "#             continue\n",
    "#         if custid not in customer_to_index.keys():\n",
    "#             test_np[ic,2] = -1\n",
    "#             continue\n",
    "#         existed_rate = train[(train[\"movie_id\"]==mvid)&(train[\"customer_id\"]==custid)]\n",
    "\n",
    "#         if (existed_rate.empty):\n",
    "#             indx_mv   = movie_to_index[mvid]\n",
    "#             indx_cust = customer_to_index[custid]\n",
    "#             pr = np.ceil(pred_ratings[indx_cust, indx_mv])\n",
    "#             if pr > 5:\n",
    "#                 test_np[ic,2] = 5\n",
    "#             else:\n",
    "#                 test_np[ic,2] = pr\n",
    "#         else:\n",
    "#             existed+=1\n",
    "#             test_np[ic,2] = existed_rate\n",
    "#         if ic%100000==0:\n",
    "#             print('ic:', ic)\n",
    "#             print(test_np)\n",
    "#             # Save movie titles\n",
    "#             fn_str = args.RESULTPATH + 'test_np_MatrixCompletition_k5'\n",
    "#             with open(fn_str, 'wb') as f:\n",
    "#                 pickle.dump(test_np, f)\n",
    "#             print('Creating movie titles time elapsed: {} sec'.format(time.time()-time_start))\n",
    "#     print('existed:', existed)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_df = pd.DataFrame(data=test_np, columns=['movie_id', 'customer_id', 'rating', 'date'])\n",
    "# fn_str = args.RESULTPATH + 'MaryZolfaghar_preds_matrix_k5.csv'\n",
    "# with open(fn_str, 'wb') as f:\n",
    "#     pickle.dump(test_df, f)\n",
    "# print('Creating movie titles time elapsed: {} sec'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# visulization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns\n",
    "\n",
    "import time\n",
    "\n",
    "\n",
    "def plot_clusters(data_plot, labels, labels_txt, final_k):\n",
    "    time_start = time.time()\n",
    "    tsne = TSNE(n_components=2, verbose=1, perplexity=40, n_iter=300)\n",
    "    tsne_results = tsne.fit_transform(data_plot)\n",
    "\n",
    "    xx = tsne_results[:,0]\n",
    "    yy = tsne_results[:,1]\n",
    "\n",
    "    plt.figure(figsize=(14,10))\n",
    "    sns.scatterplot(\n",
    "        x=xx, y=yy,\n",
    "        hue=labels,\n",
    "        palette=sns.color_palette(\"hls\", final_k),\n",
    "        legend=\"full\",\n",
    "        alpha=0.3)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(z, y)\n",
    "\n",
    "    for i, txt in enumerate(n):\n",
    "        ax.annotate(txt, (z[i], y[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_id</th>\n",
       "      <th>year_produced</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2003</td>\n",
       "      <td>Dinosaur Planet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2004</td>\n",
       "      <td>Isle of Man TT 2004 Review</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>Character</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1994</td>\n",
       "      <td>Paula Abdul's Get Up &amp; Dance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>2004</td>\n",
       "      <td>The Rise and Fall of ECW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17766</th>\n",
       "      <td>17766</td>\n",
       "      <td>2002</td>\n",
       "      <td>Where the Wild Things Are and Other Maurice Se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17767</th>\n",
       "      <td>17767</td>\n",
       "      <td>2004</td>\n",
       "      <td>Fidel Castro: American Experience</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17768</th>\n",
       "      <td>17768</td>\n",
       "      <td>2000</td>\n",
       "      <td>Epoch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17769</th>\n",
       "      <td>17769</td>\n",
       "      <td>2003</td>\n",
       "      <td>The Company</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17770</th>\n",
       "      <td>17770</td>\n",
       "      <td>2003</td>\n",
       "      <td>Alien Hunter</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17770 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movie_id year_produced  \\\n",
       "1            1          2003   \n",
       "2            2          2004   \n",
       "3            3          1997   \n",
       "4            4          1994   \n",
       "5            5          2004   \n",
       "...        ...           ...   \n",
       "17766    17766          2002   \n",
       "17767    17767          2004   \n",
       "17768    17768          2000   \n",
       "17769    17769          2003   \n",
       "17770    17770          2003   \n",
       "\n",
       "                                                   title  \n",
       "1                                        Dinosaur Planet  \n",
       "2                             Isle of Man TT 2004 Review  \n",
       "3                                              Character  \n",
       "4                           Paula Abdul's Get Up & Dance  \n",
       "5                               The Rise and Fall of ECW  \n",
       "...                                                  ...  \n",
       "17766  Where the Wild Things Are and Other Maurice Se...  \n",
       "17767                  Fidel Castro: American Experience  \n",
       "17768                                              Epoch  \n",
       "17769                                        The Company  \n",
       "17770                                       Alien Hunter  \n",
       "\n",
       "[17770 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1=[]; t2=[]; t3=[]\n",
    "with open(args.DATAPATH + 'movie_titles.txt', 'r',encoding=\"latin-1\") as reading:\n",
    "    for line in reading.readlines():\n",
    "        tokens = line.split(\",\")\n",
    "        t1.append(tokens[0])\n",
    "        t2.append(tokens[1])\n",
    "        t33 = tokens[2].split('\\n')\n",
    "        t3.append(t33[0])\n",
    "\n",
    "t1=np.asarray(t1)\n",
    "t1=t1[1:]\n",
    "t2=np.asarray(t2)\n",
    "t2=t2[1:]\n",
    "t3=np.asarray(t3)\n",
    "t3=t3[1:]\n",
    "\n",
    "titles = pd.read_fwf(args.DATAPATH + 'movie_titles.txt', delimiter= ',', \\\n",
    "                           names = [\"movie_id\", \"year_produced\", \"title\"], encoding=\"ISO-8859-1\")\n",
    "\n",
    "\n",
    "movie_titles = pd.DataFrame(titles[1:], columns=[\"movie_id\", \"year_produced\", \"title\"])\n",
    "\n",
    "movie_titles['movie_id'] = t1\n",
    "movie_titles['year_produced'] = t2\n",
    "movie_titles['title'] = t3\n",
    "\n",
    "movie_titles\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Where the Wild Things Are and Other Maurice Sendak Stories'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movieid_to_title = {movie:title for (movie, title) in zip(movie_titles['movie_id'], movie_titles['title'])}\n",
    "# movieid_to_title = {movie:year for in enumerate(movie_titles)}\n",
    "\n",
    "movieid_to_title['17766']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_to_index = {movie:indx for indx, movie in enumerate(df.columns.values)}\n",
    "customer_to_index = {customer:indx for indx, customer in enumerate(df.index.values)}\n",
    "index_to_movie = {indx:movie for indx, movie in enumerate(df.columns.values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16142, 5)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for ii in range()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_plot = Vt.T.copy()\n",
    "# km_labels = km.labels_\n",
    "km_labels=''\n",
    "# labels_txt=''\n",
    "# print('data_plot shape:', labels.shape)\n",
    " \n",
    "# plot_clusters(data_plot, km_labels, labels_txt, final_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepLearnigEEG",
   "language": "python",
   "name": "deeplearnigeeg"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
